{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downside Measures: SemiDeviation, VaR and CVaR\n",
    "\n",
    "We're going to look at a few measures of downside risk. We've already seen how to compute drawdowns, but we're going to look at 3 popular measures, and we are going to develop code to compute these and add them to our toolbox.\n",
    "\n",
    "The first measure is the simplest, which is the semideviation, which is nothing more than the volatility of the subset of returns that are negative.\n",
    "\n",
    "The code is very simple:\n",
    "\n",
    "```python\n",
    "def semideviation(r):\n",
    "    \"\"\"\n",
    "    Returns the semideviation aka negative semideviation of r\n",
    "    r must be a Series or a DataFrame, else raises a TypeError\n",
    "    \"\"\"\n",
    "    is_negative = r < 0\n",
    "    return r[is_negative].std(ddof=0)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joao.colantuono\\Investment-Management-EDHEC\\Introduction to Portfolio Construction and Analysis with Python\\notebooks_and_codem01_v02\\nb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"C:/Users/joao.colantuono/Investment-Management-EDHEC/Introduction to Portfolio Construction and Analysis with Python/\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import edhec_risk_kit_106 as erk\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfi = erk.get_hfi_returns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semideviation(r):\n",
    "    \"\"\"\n",
    "    Returns the semideviation aka negative semideviation of r\n",
    "    r must be a Series or a DataFrame, else raises a TypeError\n",
    "    \"\"\"\n",
    "    is_negative = r < 0\n",
    "    return r[is_negative].std(ddof=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convertible Arbitrage     0.019540\n",
       "CTA Global                0.012443\n",
       "Distressed Securities     0.015185\n",
       "Emerging Markets          0.028039\n",
       "Equity Market Neutral     0.009566\n",
       "Event Driven              0.015429\n",
       "Fixed Income Arbitrage    0.017763\n",
       "Global Macro              0.006579\n",
       "Long/Short Equity         0.014051\n",
       "Merger Arbitrage          0.008875\n",
       "Relative Value            0.012244\n",
       "Short Selling             0.027283\n",
       "Funds Of Funds            0.012122\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erk.semideviation(hfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convertible Arbitrage     0.019540\n",
       "CTA Global                0.012443\n",
       "Distressed Securities     0.015185\n",
       "Emerging Markets          0.028039\n",
       "Equity Market Neutral     0.009566\n",
       "Event Driven              0.015429\n",
       "Fixed Income Arbitrage    0.017763\n",
       "Global Macro              0.006579\n",
       "Long/Short Equity         0.014051\n",
       "Merger Arbitrage          0.008875\n",
       "Relative Value            0.012244\n",
       "Short Selling             0.027283\n",
       "Funds Of Funds            0.012122\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfi[hfi<0].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global Macro              0.006579\n",
       "Merger Arbitrage          0.008875\n",
       "Equity Market Neutral     0.009566\n",
       "Funds Of Funds            0.012122\n",
       "Relative Value            0.012244\n",
       "CTA Global                0.012443\n",
       "Long/Short Equity         0.014051\n",
       "Distressed Securities     0.015185\n",
       "Event Driven              0.015429\n",
       "Fixed Income Arbitrage    0.017763\n",
       "Convertible Arbitrage     0.019540\n",
       "Short Selling             0.027283\n",
       "Emerging Markets          0.028039\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erk.semideviation(hfi).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallCap    0.051772\n",
       "LargeCap    0.040245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffme = erk.get_ffme_returns()\n",
    "erk.semideviation(ffme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will not work: erk.semideviation([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VaR and CVaR\n",
    "\n",
    "We'll look at three different ways to compute Value At Risk\n",
    "\n",
    "1. Historic VaR\n",
    "2. Parametric Gaussian VaR\n",
    "3. Modified (Cornish-Fisher) VaR\n",
    "\n",
    "To compute the historic VaR at a certain level, say 5%, all we have to do is to find the number such that 5% of the returns fall below that number and 95% of the returns fall above that number. In other words, we want the 5 percentile return.\n",
    "\n",
    "Fortunately, numpy has a `np.percentile` function that computes exactly that.\n",
    "\n",
    "Add the following code to the `edhec_risk_kit.py` file:\n",
    "\n",
    "```python\n",
    "\n",
    "def var_historic(r, level=5):\n",
    "    \"\"\"\n",
    "    Returns the historic Value at Risk at a specified level\n",
    "    i.e. returns the number such that \"level\" percent of the returns\n",
    "    fall below that number, and the (100-level) percent are above\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(var_historic, level=level)\n",
    "    elif isinstance(r, pd.Series):\n",
    "        return -np.percentile(r, level)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")        \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2402568339.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [10]\u001b[1;36m\u001b[0m\n\u001b[1;33m    np.percentile(hfi, a=)\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.percentile(hfi, a=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erk.var_historic(hfi, level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for reporting purposes, it is common to invert the sign so we report a positive number to represent the _loss_ i.e. the amount that is at risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional VaR aka Beyond VaR\n",
    "\n",
    "Now that we have the VaR, the CVaR is very easy. All we need is to find the mean of the numbers that fell below the VaR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erk.cvar_historic(hfi, level=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erk.cvar_historic(ffme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Gaussian VaR\n",
    "\n",
    "The idea behind this is very simple. If a set of returns is normally distributed, we know, for instance, that 50% of the returns are below the mean and 50% are above.\n",
    "\n",
    "We also know that approx two thirds of the returns lie within 1 standard deviation. That means one third lie beyond one standard deviation from the mean. Since the normal distribution is symmetric, approximately one sixth (approx 16%) lie below one standard deviation away from the mean. Therefore, if we know the mean and standard deviation and if we assume that the returns are normally distributed, the 16% VaR would be the mean minus one standard deviation.\n",
    "\n",
    "In general we can always convert a percentile point to a z-score (which is the number of standard deviations away from the mean that a number is). Therefore, if we can convert the VaR level (such as 1% or 5%) to a z-score, we can calculate the return level where that percent of returns lie below it.\n",
    "\n",
    "`scipy.stat.norm` contains a function `ppf()` which does exactly that. It takes a percentile such as 0.05 or 0.01 and gives you the z-score corresponding to that in the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "norm.ppf(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf(.16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, all we need to do to estimate the VaR using this method is to find the z-score corresponding to percentile level, and then add that many standard deviations to the mean, to obtain the VaR.\n",
    "\n",
    "```python\n",
    "from scipy.stats import norm\n",
    "def var_gaussian(r, level=5):\n",
    "    \"\"\"\n",
    "    Returns the Parametric Gauusian VaR of a Series or DataFrame\n",
    "    \"\"\"\n",
    "    # compute the Z score assuming it was Gaussian\n",
    "    z = norm.ppf(level/100)\n",
    "    return -(r.mean() + z*r.std(ddof=0))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erk.var_gaussian(hfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erk.var_historic(hfi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cornish-Fisher Modification\n",
    "\n",
    "The Cornish-Fisher modification is an elegant and simple adjustment.\n",
    "\n",
    "The z-score tells us how many standard deviations away from the mean we need to go to find the VaR. If the returns arent normal, we know that z-score will give us an inaccurate number. The basic idea is that since we can observe the skewness and kurtosis of the data, we can adjust the z-score up or down to come up with a modifed z-score. e.g. intuitively, all other things being equal, if the skewness is negative, we'll decrease the z-score further down, and if the skewness is positive, we'll push it up.\n",
    "\n",
    "The adjusted z-score which we'll call $z_{cornishfisher}$ given by:\n",
    "\n",
    "$$ z_{cornishfisher} = z +\\frac{1}{6}(z^2-1)S + \\frac{1}{24}(z^3-3z)(K-3)-\\frac{1}{36}(2z^3-5z)S^2 $$\n",
    "\n",
    "\n",
    "We can modify the previous function by adding a \"modified\" parameter with a default value of `True` as follows. If `True` then the following piece of code is executed, which modifes `z`:\n",
    "\n",
    "```python\n",
    "    if modified:\n",
    "        # modify the Z score based on observed skewness and kurtosis\n",
    "        s = skewness(r)\n",
    "        k = kurtosis(r)\n",
    "        z = (z +\n",
    "                (z**2 - 1)*s/6 +\n",
    "                (z**3 -3*z)*(k-3)/24 -\n",
    "                (2*z**3 - 5*z)*(s**2)/36\n",
    "            )\n",
    "```\n",
    "\n",
    "The rewritten function is:\n",
    "\n",
    "```python\n",
    "from scipy.stats import norm\n",
    "def var_gaussian(r, level=5, modified=False):\n",
    "    \"\"\"\n",
    "    Returns the Parametric Gauusian VaR of a Series or DataFrame\n",
    "    If \"modified\" is True, then the modified VaR is returned,\n",
    "    using the Cornish-Fisher modification\n",
    "    \"\"\"\n",
    "    # compute the Z score assuming it was Gaussian\n",
    "    z = norm.ppf(level/100)\n",
    "    if modified:\n",
    "        # modify the Z score based on observed skewness and kurtosis\n",
    "        s = skewness(r)\n",
    "        k = kurtosis(r)\n",
    "        z = (z +\n",
    "                (z**2 - 1)*s/6 +\n",
    "                (z**3 -3*z)*(k-3)/24 -\n",
    "                (2*z**3 - 5*z)*(s**2)/36\n",
    "            )\n",
    "        \n",
    "    return -(r.mean() + z*r.std(ddof=0))\n",
    "\n",
    "```\n",
    "\n",
    "We can now compare the different methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_table = [erk.var_gaussian(hfi), \n",
    "             erk.var_gaussian(hfi, modified=True), \n",
    "             erk.var_historic(hfi)]\n",
    "comparison = pd.concat(var_table, axis=1)\n",
    "comparison.columns=['Gaussian', 'Cornish-Fisher', 'Historic']\n",
    "comparison.plot.bar(title=\"Hedge Fund Indices: VaR at 5%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in some cases, the cornish-fisher VaR is lower i.e. estimates a smaller loss than you would get from a pure gaussian assumption. That can happen if the observed skewness is positive, as is the case for \"Short Selling\" and \"Global Macro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erk.skewness(hfi).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
